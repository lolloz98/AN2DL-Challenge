{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model stats\n",
    "\n",
    "In the folder `stats_of_some_of_our_models`, you can find this notebook run on some of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SET ONCOLAB = TRUE IF WORKING ON COLAB\n",
    "onColab = False\n",
    "if onColab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/gdrive')\n",
    "  %cd /gdrive/MyDrive/University/ANN/CHALLENGE1/with_img_divided\n",
    "  !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO CHANGE DATASET_PATH AND PATH_TO_MODEL AND PREPROCESSING FUNCTION\n",
    "path_to_model = './SubmissionModel'\n",
    "dataset_path = './training'\n",
    "\n",
    "batch_size = 128\n",
    "validation_split = 0.3\n",
    "\n",
    "def tl_preprocess(x):\n",
    "  return tf.keras.applications.efficientnet.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title init seed everywhere\n",
    "seed =20\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h, img_w = (256, 256)\n",
    "\n",
    "def load_data(dontUseFun=True, fun=None, isTest = False):\n",
    "  \"\"\"\n",
    "  load data (train, val, test)\n",
    "  dontUseFun: if it's true then the data is not preprocessed. If it's false, the data is preprocessed with fun (which must not be none)\n",
    "  \"\"\"\n",
    "  image_generator = ImageDataGenerator(preprocessing_function = fun, validation_split=validation_split, \n",
    "                                          rotation_range=30,\n",
    "                                          height_shift_range=50,\n",
    "                                          width_shift_range=50,\n",
    "                                          zoom_range=0.3,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True, \n",
    "                                          fill_mode='reflect')  \n",
    "  if dontUseFun:\n",
    "    image_generator = ImageDataGenerator(validation_split=validation_split, \n",
    "                                          rotation_range=30,\n",
    "                                          height_shift_range=50,\n",
    "                                          width_shift_range=50,\n",
    "                                          zoom_range=0.3,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True, \n",
    "                                          fill_mode='reflect')  \n",
    "\n",
    "\n",
    "  # Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "  train_gen = image_generator.flow_from_directory(directory=dataset_path,\n",
    "                                                target_size=(img_h, img_w),\n",
    "                                                color_mode='rgb',\n",
    "                                                classes=None, # can be set to None\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='training',\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                seed=seed)\n",
    "\n",
    "  valid_gen = image_generator.flow_from_directory(directory=dataset_path,\n",
    "                                                target_size=(img_h, img_w),\n",
    "                                                color_mode='rgb',\n",
    "                                                classes=None, # can be set to None\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='validation',\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                seed=seed)\n",
    "  test_gen = None\n",
    "  if isTest:\n",
    "    test_image_gen = ImageDataGenerator(preprocessing_function = fun)\n",
    "    if dontUseFun:\n",
    "      test_image_gen = ImageDataGenerator(rotation_range=30)\n",
    "    \n",
    "    test_gen = test_image_gen.flow_from_directory(directory=test_path,\n",
    "                                                target_size=(img_h, img_w),\n",
    "                                                color_mode='rgb',\n",
    "                                                classes=None, # can be set to None\n",
    "                                                class_mode='categorical',\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True, # sometimes, instead of train, we use the test for training\n",
    "                                                seed=seed)\n",
    "  return train_gen, valid_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "  # x = clean_image(x)\n",
    "  if tl_preprocess:\n",
    "    return tl_preprocess(np.uint8(x))\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, valid_gen, test_gen = load_data(False, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "Y_pred = model.predict(valid_gen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(valid_gen.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replot the heatmap but this time we put vmax = 200, so that tomatoes don't cloud the colors of the heatmap and we can visualize the distribution a bit better\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm.T, xticklabels=labels, yticklabels=labels, vmax=200)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute the classification metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "target = valid_gen.classes\n",
    "predictions = Y_pred\n",
    "accuracy = accuracy_score(target, np.argmax(predictions, axis=1))\n",
    "precision = precision_score(target, np.argmax(predictions, axis=1), average='macro')\n",
    "recall = recall_score(target, np.argmax(predictions, axis=1), average='macro')\n",
    "f1 = f1_score(target, np.argmax(predictions, axis=1), average='macro')\n",
    "print('Accuracy:',accuracy.round(4))\n",
    "print('Precision:',precision.round(4))\n",
    "print('Recall:',recall.round(4))\n",
    "print('F1:',f1.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "tfk.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install visualkeras\n",
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True, spacing=20, scale_xy=5, max_xy=500)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed9b588bb7e7d983fd3ca5f90690b3f98b38ff7d3726e4a36d7a208de5b925c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
